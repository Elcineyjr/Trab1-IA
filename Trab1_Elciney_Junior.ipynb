{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 1 - Inteligência Artificial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de dados\n",
    "\n",
    "### Matrícula: 2015100346\n",
    "Dessa forma, devido ao final da matrícula ser 6, a base de dados será composta pelos 10 descritores de Fourier e os 7 descritores de Hu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "355    metalica400\n",
      "356    metalica400\n",
      "357    metalica400\n",
      "358    metalica400\n",
      "359    metalica400\n",
      "          ...     \n",
      "656    metalica250\n",
      "657    metalica250\n",
      "658    metalica250\n",
      "659    metalica250\n",
      "660    metalica250\n",
      "Length: 297, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probmax</th>\n",
       "      <th>energia</th>\n",
       "      <th>entropia</th>\n",
       "      <th>contraste</th>\n",
       "      <th>homogeneidade</th>\n",
       "      <th>correlacao</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.890374</td>\n",
       "      <td>3.170342</td>\n",
       "      <td>6.571618</td>\n",
       "      <td>-30.712990</td>\n",
       "      <td>3.763049</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.874335</td>\n",
       "      <td>3.056052</td>\n",
       "      <td>7.561434</td>\n",
       "      <td>-37.105195</td>\n",
       "      <td>3.722622</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      probmax   energia  entropia  contraste  homogeneidade  correlacao\n",
       "id                                                                     \n",
       "355  0.890374  3.170342  6.571618 -30.712990       3.763049    0.000304\n",
       "356  0.874335  3.056052  7.561434 -37.105195       3.722622    0.000269"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leitura dos dados\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/VitorBonella/PL-Dataset/main/dataset.csv',sep=\";\") \n",
    "\n",
    "# Transformando a coluna id no índice da tabela\n",
    "df.set_index('id', inplace=True)\n",
    "\n",
    "# Lista de descritores\n",
    "FOURIER = ['df01', 'df02', 'df03', 'df04','df05', 'df06', 'df07', 'df08', 'df09', 'df10']\n",
    "HU = ['i1', 'i2', 'i3', 'i4','i5', 'i6', 'i7']\n",
    "HARALICK = ['probmax', 'energia', 'entropia', 'contraste','homogeneidade', 'correlacao']\n",
    "\n",
    "# Descritores que serão usados nesse trabalho\n",
    "dataset = df[FOURIER + HU] \n",
    "\n",
    "# Transformação dos dados de string para float devido ao uso da vírgula ao invés do ponto\n",
    "dataset = dataset.apply(lambda x: x.str.replace(',', '.').astype(float), axis=1)\n",
    "\n",
    "# Criação das classes baseada no tipo da lâmpada e na potência\n",
    "classes = df['tipo_lampada'].str.replace(\" \", \"\") + df['potencia'].astype(str) \n",
    "\n",
    "# Adiciona a classe ao data frame da base de dados\n",
    "# dataset['classe'] = df['tipo_lampada'].str.replace(\" \", \"\") + df['potencia'].astype(str) \n",
    "\n",
    "# Define a base de dados e as classes target\n",
    "dataset_X = dataset\n",
    "dataset_Y = classes\n",
    "\n",
    "# from sklearn import datasets\n",
    "# dataset = datasets.load_breast_cancer()\n",
    "# dataset_X = dataset.data\n",
    "# dataset_Y = dataset.target\n",
    "\n",
    "print(classes)\n",
    "dataset.head(2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(scores):\n",
    "    print(f'\\nMédia: {scores.mean():.5f}, Desvio Padrão: {scores.std():.5f}')\n",
    "\n",
    "    inf, sup = stats.norm.interval(0.95, loc=scores.mean(), \n",
    "                               scale=scores.std()/np.sqrt(len(scores)))\n",
    "    \n",
    "    print(f'Intervalo de confiança (95%): [{inf:.5f},{sup:.5f}]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZeroR (ZR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16666667 0.13333333 0.16666667 0.16666667 0.16666667 0.16666667\n",
      " 0.16666667 0.17241379 0.17241379 0.17241379 0.16666667 0.13333333\n",
      " 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.17241379\n",
      " 0.17241379 0.17241379 0.16666667 0.13333333 0.16666667 0.16666667\n",
      " 0.16666667 0.16666667 0.16666667 0.17241379 0.17241379 0.17241379]\n",
      "\n",
      "Média: 0.16506, Desvio Padrão: 0.01088\n",
      "Intervalo de confiança (95%): [0.16116,0.16895]\n"
     ]
    }
   ],
   "source": [
    "zR = DummyClassifier()\n",
    "\n",
    "pipeline = Pipeline([('transformer', StandardScaler()), ('estimator', zR)])\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=36851234)\n",
    "\n",
    "scores_zR = cross_val_score(pipeline, dataset_X, dataset_Y, scoring='accuracy', cv = rkf)\n",
    "\n",
    "print(scores_zR)\n",
    "\n",
    "classification_report(scores_zR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging (BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.36666667 0.53333333 0.33333333 0.4        0.36666667\n",
      " 0.23333333 0.5862069  0.4137931  0.51724138 0.5        0.4\n",
      " 0.46666667 0.53333333 0.4        0.46666667 0.43333333 0.31034483\n",
      " 0.34482759 0.4137931  0.53333333 0.43333333 0.36666667 0.43333333\n",
      " 0.36666667 0.36666667 0.5        0.48275862 0.48275862 0.4137931 ]\n",
      "\n",
      "Média: 0.43552, Desvio Padrão: 0.08763\n",
      "Intervalo de confiança (95%): [0.40416,0.46687]\n"
     ]
    }
   ],
   "source": [
    "grade = {'estimator__n_estimators':[3, 9, 15, 21]}\n",
    "\n",
    "# TODO\n",
    "# Talvez usar um estimador diferente no final do ensemble\n",
    "# Opções: Decision Tree, Random Forest, K-Nearest Neighbors (KNN), Support Vector Machines (SVM)\n",
    "bg = BaggingClassifier(estimator=GaussianNB(), random_state=0)\n",
    "\n",
    "pipeline = Pipeline([('transformer', StandardScaler()), ('estimator', bg)])\n",
    "\n",
    "gs = GridSearchCV(estimator=pipeline, param_grid=grade, scoring='accuracy', cv=4)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=36851234)\n",
    "\n",
    "scores_BA = cross_val_score(gs, dataset_X, dataset_Y, scoring='accuracy', cv = rkf)\n",
    "\n",
    "print(scores_BA)\n",
    "\n",
    "classification_report(scores_BA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost (AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2        0.33333333 0.4        0.23333333 0.5        0.26666667\n",
      " 0.33333333 0.4137931  0.31034483 0.4137931  0.36666667 0.4\n",
      " 0.33333333 0.3        0.36666667 0.2        0.4        0.24137931\n",
      " 0.37931034 0.37931034 0.5        0.43333333 0.5        0.5\n",
      " 0.4        0.4        0.36666667 0.37931034 0.4137931  0.27586207]\n",
      "\n",
      "Média: 0.36467, Desvio Padrão: 0.08294\n",
      "Intervalo de confiança (95%): [0.33500,0.39435]\n"
     ]
    }
   ],
   "source": [
    "grade = {'estimator__n_estimators':[3, 9, 15, 21]}\n",
    "\n",
    "# TODO\n",
    "# Talvez usar um estimador diferente no final do ensemble\n",
    "# Opções: Decision Tree, Random Forest, K-Nearest Neighbors (KNN), Support Vector Machines (SVM)\n",
    "adb = AdaBoostClassifier(estimator=GaussianNB(), random_state=0)\n",
    "\n",
    "pipeline = Pipeline([('transformer', StandardScaler()), ('estimator', adb)])\n",
    "\n",
    "gs = GridSearchCV(estimator=pipeline, param_grid=grade, scoring='accuracy', cv=4)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=36851234)\n",
    "\n",
    "scores_AB = cross_val_score(gs, dataset_X, dataset_Y, scoring='accuracy', cv = rkf)\n",
    "\n",
    "print(scores_AB)\n",
    "\n",
    "classification_report(scores_AB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8        0.33333333 0.7        0.6        0.5        0.66666667\n",
      " 0.56666667 0.62068966 0.62068966 0.68965517 0.4        0.43333333\n",
      " 0.73333333 0.63333333 0.56666667 0.6        0.56666667 0.65517241\n",
      " 0.55172414 0.68965517 0.53333333 0.56666667 0.63333333 0.5\n",
      " 0.53333333 0.5        0.66666667 0.44827586 0.51724138 0.51724138]\n",
      "\n",
      "Média: 0.57812, Desvio Padrão: 0.10096\n",
      "Intervalo de confiança (95%): [0.54200,0.61425]\n"
     ]
    }
   ],
   "source": [
    "grade = {'randomForest__n_estimators': [3, 9, 15, 21]}\n",
    "\n",
    "rF = RandomForestClassifier()\n",
    "\n",
    "pipeline = Pipeline([('transformer', StandardScaler()), ('randomForest', rF)])\n",
    "\n",
    "gs = GridSearchCV(estimator=pipeline, param_grid=grade, scoring='accuracy', cv = 4)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=36851234)\n",
    "\n",
    "scores_RF = cross_val_score(gs, dataset_X, dataset_Y, scoring='accuracy', cv = rkf)\n",
    "\n",
    "print(scores_RF)\n",
    "\n",
    "classification_report(scores_RF)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogeneous Pooling (HP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class HeterogeneousPoolingClassifier(BaseEstimator):\n",
    "    def __init__(self, n_samples):\n",
    "        super().__init__()\n",
    "        self.n_samples = n_samples\n",
    "        self.classifiers = []\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        x_train, y_train = check_X_y(x_train, y_train)\n",
    "        classes = np.unique(y_train)\n",
    "        self.class_order = self._get_class_order(y_train)\n",
    "\n",
    "        for i in range(self.n_samples):\n",
    "            # First iteration uses the original base for training\n",
    "            if i == 0:\n",
    "                current_x_train, current_y_train = x_train, y_train\n",
    "            else:\n",
    "                # Resample the training data with replacement\n",
    "                current_x_train, current_y_train = resample(x_train, y_train, replace=True, random_state=i-1)\n",
    "\n",
    "            dt_classifier = DecisionTreeClassifier()\n",
    "            dt_classifier.fit(current_x_train, current_y_train)\n",
    "            self.classifiers.append(dt_classifier)\n",
    "\n",
    "            nb_classifier = GaussianNB()\n",
    "            nb_classifier.fit(current_x_train, current_y_train)\n",
    "            self.classifiers.append(nb_classifier)\n",
    "\n",
    "            knn_classifier = KNeighborsClassifier()\n",
    "            knn_classifier.fit(current_x_train, current_y_train)\n",
    "            self.classifiers.append(knn_classifier)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((X.shape[0], len(self.class_order)))\n",
    "\n",
    "        for i in enumerate(self.class_order):\n",
    "            for classifier in enumerate(self.classifiers[i::len(self.class_order)]):\n",
    "                # Make predictions using each classifier for the current class\n",
    "                predictions[:, i] += classifier.predict(X)\n",
    "\n",
    "        final_predictions = []\n",
    "        for pred_row in predictions:\n",
    "            class_votes = Counter(pred_row)\n",
    "            max_vote = max(class_votes.values())\n",
    "            tie_classes = [class_label for class_label, votes in class_votes.items() if votes == max_vote]\n",
    "\n",
    "            if len(tie_classes) > 1:\n",
    "                # If multiple classes have the same highest vote, choose the most frequent class in the training data\n",
    "                tie_class_counts = Counter(y)\n",
    "                max_tie_vote = max([tie_class_counts[class_label] for class_label in tie_classes])\n",
    "                most_frequent_tie_classes = [class_label for class_label in tie_classes if tie_class_counts[class_label] == max_tie_vote]\n",
    "                final_predictions.append(max(most_frequent_tie_classes, key=lambda x: np.count_nonzero(self.class_order == x)))\n",
    "            else:\n",
    "                final_predictions.append(tie_classes[0])\n",
    "\n",
    "        return np.array(final_predictions)\n",
    "\n",
    "    def _get_class_order(self, y):\n",
    "        class_counts = Counter(y)\n",
    "        sorted_classes = sorted(class_counts, key=class_counts.get, reverse=True)\n",
    "        return np.array(sorted_classes)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hp\n",
    "\n",
    "O pseudo código a seguir mostra como o HP é obtido a partir de uma base de dados de treino:\n",
    "\n",
    "- Obter e armazenar a ordenação das classes de acordo com a ocorrência nos exemplos na\n",
    "base de treino (ordenar decrescentemente da mais frequente para a menos frequente)\n",
    "- Para cada um dos n_samples faça\n",
    "    - Se for a primeira iteração então\n",
    "        - Usar a base original para treino dos classificadores\n",
    "    - Senão\n",
    "        - Montar uma base de treino de mesmo tamanho da original coletando aleatoriamente exemplos da base original com reposição\n",
    "    - Fim-se\n",
    "    - Treinar os classificadores NN, NB, DT na base de treino corrente e incluí-los no combinado de classificadores\n",
    "- Fim-para\n",
    "\n",
    "### Classificação final\n",
    "\n",
    "O pseudo código seguinte mostra como o combinado HP é usado para classificar um exemplo\n",
    "da base de dados de teste:\n",
    "\n",
    "- Para cada um dos classificadores individuais do combinado faça\n",
    "    - Obter a classificação do exemplo usando o classificador individual e armazenar a classe selecionada\n",
    "- Fim-para\n",
    "- Contar quantas vezes cada classe foi selecionada e obter a(s) mais votada(s)\n",
    "- Se mais de uma classe for a mais votada então\n",
    "    - Retornar a classe mais votada mais frequente na base de treino dentre as que empataram\n",
    "- Senão\n",
    "    - Retornar a classe mais votada\n",
    "- Fim-se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Média: 0.16506, Desvio Padrão: 0.01088\n",
      "Intervalo de confiança (95%): [0.16116,0.16895]\n",
      "\n",
      "Média: 0.43552, Desvio Padrão: 0.08763\n",
      "Intervalo de confiança (95%): [0.40416,0.46687]\n",
      "\n",
      "Média: 0.36467, Desvio Padrão: 0.08294\n",
      "Intervalo de confiança (95%): [0.33500,0.39435]\n",
      "\n",
      "Média: 0.57812, Desvio Padrão: 0.10096\n",
      "Intervalo de confiança (95%): [0.54200,0.61425]\n"
     ]
    }
   ],
   "source": [
    "classification_report(scores_zR)\n",
    "classification_report(scores_BA)\n",
    "classification_report(scores_AB)\n",
    "classification_report(scores_RF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
